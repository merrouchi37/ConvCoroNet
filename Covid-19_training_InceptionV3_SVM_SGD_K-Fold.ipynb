{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a8480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8cb9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Optimizer, Adam,RMSprop, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#import argparse\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d11abf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('new_3000_data_train_224.npy')\n",
    "labels_train = np.load('new_3000_labels_train_224.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f35a6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69ab40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling Data\n",
    "np.random.seed(12345)\n",
    "indx=np.arange(data_train.shape[0])          \n",
    "np.random.shuffle(indx)\n",
    "data_train = data_train[indx]\n",
    "labels_train = labels_train[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bc161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model( ):\n",
    "    lam = l2(1e-3)\n",
    "    baseModel = InceptionV3(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "    for layer in baseModel.layers:\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', lam)\n",
    "    x = baseModel.output\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=lam)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(3, activation=\"linear\", kernel_regularizer=lam)(x) \n",
    "    \n",
    "    model = Model(inputs=baseModel.input, outputs=x)\n",
    "    for layer in baseModel.layers: \n",
    "        layer.trainable = False\n",
    "    \n",
    "    return model\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d67c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(labels_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeeef40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_acc_loss\n",
    "from utils import evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086e155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits =5, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "validation_loss = []\n",
    "\n",
    "base_model = \"InceptionV3_SVM\"\n",
    "save_dir = 'covid19_models_cross_val_' + base_model + '/'\n",
    "\n",
    "fold_var = 1\n",
    "for train_index, val_index in skf.split(np.zeros(len(data_train)),labels):\n",
    "  \n",
    "    training_data = data_train[train_index]\n",
    "    training_labels = labels_train[train_index]\n",
    "    validation_data = data_train[val_index]\n",
    "    validation_labels = labels_train[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "    opt = SGD()\n",
    "    model.compile(loss=\"categorical_hinge\", optimizer=opt, metrics=[\"acc\"])\n",
    "    \n",
    "    best_model_path = save_dir + 'model_' + base_model + '_fold_' + str(fold_var) + '.h5'\n",
    "    mcp_save = ModelCheckpoint(best_model_path, save_best_only=True, monitor='val_acc', mode='max', verbose=1)\n",
    "    callbacks = [ mcp_save]\n",
    "    \n",
    "    print(\"[INFO] training K-Fold...step: \" + str(fold_var))\n",
    "    \n",
    "    histories = []\n",
    "    lrs = [ 0.001, 0.0002, 0.00004]\n",
    "    #lesEpochs = [40, 40, 20]\n",
    "    lesEpochs = [2, 2, 2]\n",
    "    BS_tr=32\n",
    "    BS_val = 32\n",
    "    for i in range(len(lrs)):\n",
    "        opt.learning_rate = lrs[i]\n",
    "        \n",
    "        H = model.fit(\n",
    "            trainAug.flow(training_data, training_labels, batch_size=BS_tr),\n",
    "            #steps_per_epoch=len(training_data) // BS_tr ,\n",
    "            validation_data=(validation_data, validation_labels),\n",
    "            #validation_steps=len(validation_data) // BS_val ,\n",
    "            epochs=lesEpochs[i], callbacks=callbacks,\n",
    "            shuffle=True)\n",
    "        histories.append(H.history)\n",
    "    \n",
    "    #np.save(save_dir + 'history_' + base_model + '-' + str(fold_var) + '.npy', Hs.history)\n",
    "    dict_history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    for hist in histories:\n",
    "        for key , value in dict_history.items():\n",
    "            for a in hist[key]:\n",
    "                dict_history[key].append(a )\n",
    "    \n",
    "    plot_acc_loss(dict_history, np.sum(lesEpochs))\n",
    "\n",
    "    #Loading best model\n",
    "    model.load_weights(best_model_path)\n",
    "    #Saving weights\n",
    "    model.save_weights(save_dir + 'model_' + base_model + '_fold_' + str(fold_var) + '_weights.h5')\n",
    "    results = model.evaluate(validation_data, validation_labels)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    \n",
    "    validation_accuracy.append(results['acc'])\n",
    "    validation_loss.append(results['loss'])\n",
    "                       \n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "\n",
    "    evaluation_metrics(model, validation_data, validation_labels, fold_var, BS_val)\n",
    "    \n",
    "    #Saving accuracy and loss curves\n",
    "    np.save(save_dir + base_model + \"_fold_\" + str(fold_var) + \"_acc.npy\", dict_history[\"acc\"])\n",
    "    np.save(save_dir + base_model + \"_fold_\" + str(fold_var) + \"_loss.npy\", dict_history[\"loss\"])\n",
    "    np.save(save_dir + base_model + \"_fold_\" + str(fold_var) + \"_val_acc.npy\", dict_history[\"val_acc\"])\n",
    "    np.save(save_dir + base_model + \"_fold_\" + str(fold_var) + \"_val_loss.npy\", dict_history[\"val_loss\"])    \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold_var = fold_var + 1 # Next fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average accuracy : \", np.mean(validation_accuracy))\n",
    "print(\"Average loss : \", np.mean(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e093a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.8 (tfdl)",
   "language": "python",
   "name": "tfdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
