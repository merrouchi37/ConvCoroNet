{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73cf7094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "#print(keras.__version__)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de149b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Optimizer, Adam,RMSprop, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#import argparse\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import gc\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb233fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('new_3000_data_train_224.npy')\n",
    "labels_train = np.load('new_3000_labels_train_224.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97023a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c2c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling Data\n",
    "np.random.seed(12345)\n",
    "indx=np.arange(data_train.shape[0])          \n",
    "np.random.shuffle(indx)\n",
    "data_train = data_train[indx]\n",
    "labels_train = labels_train[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16240b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90dc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model( opt ):\n",
    "    lam = l2(1e-5)\n",
    "    baseModel = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in baseModel.layers:\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', lam)\n",
    "    x = baseModel.output\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=lam)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(3, activation=\"softmax\", kernel_regularizer=lam)(x) #, kernel_regularizer=l2(0.0001)\n",
    "\n",
    "    model = Model(inputs=baseModel.input, outputs=x)\n",
    "    for layer in baseModel.layers: \n",
    "        layer.trainable =  True #False\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"acc\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cbc504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5b673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(labels_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a322a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_acc_loss\n",
    "from utils import evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab76332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits =5, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71fde488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Un sous-répertoire ou un fichier covid19_models_cross_val_InceptionV3_RMSprop existe déjà.\n",
      "Un sous-répertoire ou un fichier covid19_models_cross_val_InceptionV3_Adam existe déjà.\n",
      "Un sous-répertoire ou un fichier covid19_models_cross_val_InceptionV3_SGD existe déjà.\n"
     ]
    }
   ],
   "source": [
    "!mkdir covid19_models_cross_val_InceptionV3_RMSprop\n",
    "!mkdir covid19_models_cross_val_InceptionV3_Adam\n",
    "!mkdir covid19_models_cross_val_InceptionV3_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a23485",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "validation_loss = []\n",
    "\n",
    "#base_model_opt = \"InceptionV3_SGD\"\n",
    "#opt = SGD()\n",
    "\n",
    "#base_model_opt = \"InceptionV3_RMSprop\"\n",
    "#opt = RMSprop()\n",
    "\n",
    "base_model_opt = \"InceptionV3_Adam\"\n",
    "opt = Adam()\n",
    "\n",
    "save_dir = 'covid19_models_cross_val_' + base_model_opt +'/' # A base directory to save results and models\n",
    "\n",
    "\n",
    "\n",
    "fold_var = 1\n",
    "for train_index, val_index in skf.split(np.zeros(len(data_train)),labels):\n",
    "  \n",
    "    training_data = data_train[train_index]\n",
    "    training_labels = labels_train[train_index]\n",
    "    validation_data = data_train[val_index]\n",
    "    validation_labels = labels_train[val_index]\n",
    "\n",
    "    model = create_model(opt)\n",
    "        \n",
    "    best_model_path = save_dir + 'model_' + base_model_opt + '_fold_' + str(fold_var) + '.h5'\n",
    "    mcp_save = ModelCheckpoint(best_model_path, save_best_only=True, monitor='val_acc', mode='max', verbose=1)\n",
    "    callbacks = [ mcp_save]\n",
    "    print(\"[INFO] training K-Fold...step: \" + str(fold_var))\n",
    "    \n",
    "    histories = []\n",
    "    if opt == SGD():\n",
    "        lrs = [ 0.001, 0.0001, 0.00001] # For SGD\n",
    "    else:\n",
    "        lrs = [ 0.0001, 0.00001, 0.000001] # For RMSprop and Adam\n",
    "            \n",
    "    lesEpochs = [40, 40, 20]\n",
    "        \n",
    "    BS_tr=32\n",
    "    BS_val = 32\n",
    "    for i in range(len(lrs)):\n",
    "        opt.learning_rate = lrs[i]\n",
    "        H = model.fit(\n",
    "            trainAug.flow(training_data, training_labels, batch_size=BS_tr),\n",
    "            #steps_per_epoch=len(training_data) // BS_tr ,\n",
    "            validation_data=(validation_data, validation_labels),\n",
    "            #validation_steps=len(validation_data) // BS_val ,\n",
    "            epochs=lesEpochs[i], callbacks=callbacks, \n",
    "            shuffle=True)\n",
    "        histories.append(H.history)\n",
    "    \n",
    "    #np.save(save_dir + 'history_' + base_model + '-' + str(fold_var) + '.npy', Hs.history)\n",
    "    dict_history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    for hist in histories:\n",
    "        for key , value in dict_history.items():\n",
    "            for a in hist[key]:\n",
    "                dict_history[key].append(a )\n",
    "    \n",
    "    plot_acc_loss(dict_history, np.sum(lesEpochs))\n",
    "\n",
    "    #Loading best model\n",
    "    model.load_weights(best_model_path)\n",
    "    #Saving weights\n",
    "    model.save_weights(save_dir + 'model_' + base_model_opt + '_fold_' + str(fold_var) + '_weights.h5')\n",
    "    results = model.evaluate(validation_data, validation_labels)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    \n",
    "    validation_accuracy.append(results['acc'])\n",
    "    validation_loss.append(results['loss'])\n",
    "                       \n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "\n",
    "    evaluation_metrics(model, validation_data, validation_labels, fold_var, BS_val)\n",
    "    \n",
    "    #Saving accuracy and loss curves\n",
    "    np.save(save_dir + base_model_opt + \"_fold_\" + str(fold_var) + \"_acc.npy\", dict_history[\"acc\"])\n",
    "    np.save(save_dir + base_model_opt + \"_fold_\" + str(fold_var) + \"_loss.npy\", dict_history[\"loss\"])\n",
    "    np.save(save_dir + base_model_opt + \"_fold_\" + str(fold_var) + \"_val_acc.npy\", dict_history[\"val_acc\"])\n",
    "    np.save(save_dir + base_model_opt + \"_fold_\" + str(fold_var) + \"_val_loss.npy\", dict_history[\"val_loss\"])    \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold_var = fold_var + 1 # Next fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49385356",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average accuracy : \", np.mean(validation_accuracy))\n",
    "print(\"Average loss : \", np.mean(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43daf5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8715e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812a0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.8 (tfdl)",
   "language": "python",
   "name": "tfdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
